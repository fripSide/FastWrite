\section{Introduction}

The rise of generative AI has transformed academic writing, This is a test sentence added by the agent to verify editing. but for computer systems and security researchers, this transition remains challenging.

\subsection{The Challenge}

Top-tier systems and security venues (e.g., S\&P, OSDI, Usenix Security, and CCS) demand rigorous logical flow, authoritative tone, and terminological precision. However, existing collaborative platforms like Overleaf lack integration with domain-aware AI assistants capable of enforcing these standards. Consequently, authors face a significant trade-off between collaborative efficiency and writing quality.

Generic Large Language Models (LLMs) fail to bridge this gap. They frequently generate verbose or hallucinatory content, imposing high manual verification overhead. Furthermore, offloading unpublished drafts to external, cloud-based model providers introduces unacceptable privacy and data sovereignty risks. These limitations necessitate a secure, context-aware solution that integrates directly into the LaTeX workflow to guarantee technical accuracy and structural integrity without compromising confidentiality.

\subsection{Our Solution: FastWrite}
To address these challenges, we introduce \textbf{FastWrite}, a privacy-focused, local-first LaTeX editor.
FastWrite bridges the gap between traditional editors and modern AI capabilities.
Unlike plugins that merely overlay text, FastWrite parses the LaTeX structure to offer context-aware suggestions.
Our contributions are as follows:

\begin{itemize}
    \item \textbf{Deep LaTeX Integration:} FastWrite understands sections, figures, and citations, ensuring that AI suggestions are syntactically correct and contextually relevant.
    \item \textbf{Granular AI Modes:} We propose three distinct interaction modes---Diagnose, Refine, and QuickFix---tailored to different stages of the writing process.
    \item \textbf{Local-First Architecture:} By running the backend locally, FastWrite ensures that the full paper draft never leaves the user's machine unless explicitly sent to an LLM provider for processing specific segments.
\end{itemize}